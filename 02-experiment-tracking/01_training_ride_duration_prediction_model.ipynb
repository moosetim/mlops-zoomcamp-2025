{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f8625b2",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2859a5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.1\n"
     ]
    }
   ],
   "source": [
    "!python -V # --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75c64617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "import pickle # To be able to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e10d866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/23 19:11:13 INFO mlflow.tracking.fluent: Experiment with name 'nyc-taxi-experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/workspaces/mlops-zoomcamp-2025/02-experiment-tracking/mlruns/1', creation_time=1748027473246, experiment_id='1', last_update_time=1748027473246, lifecycle_stage='active', name='nyc-taxi-experiment', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri('sqlite:///mlflow.db')\n",
    "mlflow.set_experiment('nyc-taxi-experiment') # Set experiment name. MLflow will create it if it doesn't exist and assigns all runs to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9461b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output:\n",
    "# Experiment with name 'nyc-taxi-experiment' does not exist. Creating a new experiment.\n",
    "# <Experiment: artifact_location='/workspaces/mlops-zoomcamp-2025/02-experiment-tracking/mlruns/1', creation_time=1748027473246, experiment_id='1', last_update_time=1748027473246, lifecycle_stage='active', name='nyc-taxi-experiment', tags={}>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c277593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "# hyperopt - library that uses Bayesian optimisation to find the best hyperparameters\n",
    "# fmin - method to minimise the objective function\n",
    "# tpe - Tree-structured Parzen Estimator, a Bayesian optimisation algorithm\n",
    "# hp - hyperopt library for defining the search space\n",
    "# STATUS_OK - status of the trial\n",
    "# Trials - class to keep track of the trials\n",
    "# scope - used to define the search space for hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ee903d",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a928f3e",
   "metadata": {},
   "source": [
    "Use the following commands to download the data locally: \n",
    "- `mkdir /workspaces/mlops-zoomcamp-2025/01-intro/data`\n",
    "  \n",
    "- `cd 01-intro/data`\n",
    "  \n",
    "- `wget https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-01.parquet` - download data for January, 2021\n",
    "\n",
    "- `wget https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-02.parquet` - download data for February, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7883bfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.6 ms, sys: 18.1 ms, total: 60.7 ms\n",
      "Wall time: 54.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "path_to_data = './data/green_tripdata_2021-01.parquet'\n",
    "df = pd.read_parquet(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97be40eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate target variable: trip duration\n",
    "df['duration'] = df['lpep_dropoff_datetime'] - df['lpep_pickup_datetime']\n",
    "\n",
    "# Convert duration to minutes\n",
    "df['duration'] = df['duration'].apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "# Check percentage of data within 1 and 60 minute durations\n",
    "trip_duration_1_to_60_condition = (df['duration'] >= 1) & (df['duration'] <= 60)\n",
    "\n",
    "# Filter the data to only include trips with duration between 1 and 60 minutes\n",
    "df = df.loc[trip_duration_1_to_60_condition]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01dc9ac",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35401f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21a3247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one-hot encoding to convert categorical columns to numerical\n",
    "# One-hot encoding converts strings into categorical variables. Convert int64 to string first\n",
    "\n",
    "df[categorical] = df[categorical].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ac05b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 266 ms, sys: 15.9 ms, total: 282 ms\n",
      "Wall time: 291 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "train_dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "# Target variable\n",
    "target = 'duration'\n",
    "y_train = df[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9afe61d",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abc16f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 195 ms, sys: 1.97 ms, total: 197 ms\n",
      "Wall time: 31.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.827368941909368"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = lr.predict(X_train)\n",
    "\n",
    "# Evaluate the performance of the model: use RMSE \n",
    "root_mean_squared_error(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549c4a33",
   "metadata": {},
   "source": [
    "# Function to pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba8a953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    # Read in the data\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    # Calculate target variable: trip duration\n",
    "    df['duration'] = df['lpep_dropoff_datetime'] - df['lpep_pickup_datetime']\n",
    "\n",
    "    # Convert duration to minutes\n",
    "    df['duration'] = df['duration'].apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    # Check percentage of data within 1 and 60 minute durations\n",
    "    trip_duration_1_to_60_condition = (df['duration'] >= 1) & (df['duration'] <= 60)\n",
    "    df = df.loc[trip_duration_1_to_60_condition]\n",
    "\n",
    "    # Feature engineering\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c568a95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 455 ms, sys: 47.9 ms, total: 503 ms\n",
      "Wall time: 468 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "df_train = read_dataframe('./data/green_tripdata_2021-01.parquet')\n",
    "df_val = read_dataframe('./data/green_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f46da74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73908, 61921)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the size of dataframes\n",
    "len(df_train), len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71e6e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts) # Notice, that we only transform the validation set, not fitting required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11e01f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00c6cdc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.496651120492572"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "root_mean_squared_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fe463a",
   "metadata": {},
   "source": [
    "# LASSO Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51cb9157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.212583224318818"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default parameters of Lasso\n",
    "lr = Lasso()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "root_mean_squared_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de89ccac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.481255832596219"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change default parameters of Lasso\n",
    "lr = Lasso(alpha=0.001)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "root_mean_squared_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3ccaac",
   "metadata": {},
   "source": [
    "# Keeping track of runs with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31ea3385",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(): # Start a new run. Everything below will be associated with this run\n",
    "    # Start logging information\n",
    "    mlflow.set_tag('developer', 'timur')\n",
    "\n",
    "    mlflow.log_param('train-data-path', './data/green_tripdata_2021-01.parquet') # Any parameters relevant to the model\n",
    "    mlflow.log_param('valid-data-path', './data/green_tripdata_2021-02.parquet') \n",
    "\n",
    "    \n",
    "    alpha = 0.1\n",
    "    mlflow.log_param('alpha', alpha)\n",
    "    lr = Lasso(alpha=alpha)\n",
    "    lr.fit(X_train, y_train)    \n",
    "    y_pred = lr.predict(X_val)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "    mlflow.log_metric('rmse', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a32c00",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70581c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use XGBost, we need to convert the data into DMatrix format\n",
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa04b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function\n",
    "def objective(params):\n",
    "    # params - set of hyperparameters for XGBoost\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", \"xgboost\")\n",
    "        mlflow.log_params(params)\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=1000,\n",
    "            evals=[(valid, 'validation')],\n",
    "            early_stopping_rounds=50\n",
    "        )\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    return {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e500fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for hyperparameters\n",
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0), # values between exp(-3) and exp(0), -0.05 and 1\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    'objective': 'reg:linear', # reg:linear is now deprecated in favor of reg:squarederror\n",
    "    'seed': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dad68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the information about objective function and search space to fmin\n",
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest, # Alogorithm to use for hyperparameter tuning\n",
    "    max_evals=50,\n",
    "    trials=Trials(),\n",
    "    verbose=False # Set to True to see the progress of the trials\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01292684",
   "metadata": {},
   "source": [
    "# Train the model with the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf64c780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the results of the 50 runs, get the model with the lowest RMSE\n",
    "\n",
    "params = {\n",
    "    \"learning_rate\": 0.14539214740033007,\n",
    "    \"max_depth\": 11,\n",
    "    \"min_child_weight\": 3.4888218672829265,\n",
    "    \"objective\": \"reg:linear\",\n",
    "    \"reg_alpha\": 0.012807793708352775,\n",
    "    \"reg_lambda\": 0.25871874053728533,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "# Use autologging to log the parameters. This simplifies the process of logging parameters and metrics\n",
    "mlflow.xgboost.autolog()\n",
    "\n",
    "booster = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=train,\n",
    "    num_boost_round=1000,\n",
    "    evals=[(valid, 'validation')],\n",
    "    early_stopping_rounds=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1674affb",
   "metadata": {},
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "eaf732f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.09 ms, sys: 0 ns, total: 7.09 ms\n",
      "Wall time: 15.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Save the dictionary vectoriser and selected model\n",
    "# mode wb - write binary\n",
    "with open('./models/lin_reg.bin', 'wb') as f_out:\n",
    "    pickle.dump((dv, lr), f_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
